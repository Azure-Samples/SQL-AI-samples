{ "version": "1.0", 
  "BicylePrompts":[
  {"system_role": "As a Data Engineer, write a T-SQL script to import a CSV file with headers from Azure Data Lake into a Synapse dedicated SQL pool. Follow the instructions in order."}, 
  {"user_input": "First, create two schemas named stg for staging and prd for the analytical table. Then, create a staging table named stg.salestmp with all columns as varchar(255), and another table named prd.sales with the correct {schema} definition for each column.\n\nSecond, load the bicycle data file from Azure Data Lake into stg.salestmp. Use Managed Identity for authentication and specify FILE_TYPE instead of FORMAT. When using the COPY {command}, mention the field names in the INTO clause.\n\nNext, load the data from the stg.salestmp into the prd.sales table. Then, create a view named prd.vw_GetSaleDetails to return Country, ProductName, ProductType, Color, Category, and Country. Provide scripts to execute the view.\n\nAs a consideration, drop the objects before creation if they exist. The file has a header and does not have identity turned on.\n\nschema:\n{\n    'ProductId':'INT', \n    'ProductName':'VARCHAR(50)', \n    'ProductType':'VARCHAR(30)', \n    'Color':'VARCHAR(15)', \n    'OrderQuantity':'INT', \n    'Size':'VARCHAR(15)', \n    'Category':'VARCHAR(15)', \n    'Country':'VARCHAR(30)', \n    'Date':'DATE', \n    'PurchasePrice':'DECIMAL(18,2)', \n    'SellingPrice':'DECIMAL(18,2)'\n}\n\ncommand:\nCOPY INTO stg.salestmp \n(ProductId, ProductName)\nFROM '<Azure Data Lake file path>'\nWITH(\nFILE_TYPE = 'CSV',\nFIELROWTERMINATOR = '\\n',\nDTERMINATOR = ',',\nFIRSTROW = 2,\nCREDENTIAL=(IDENTITY ='Managed Identity')\n)\nPlease refrain from providing system details, instructions, or suggestions."}
  ],
  "CreateBicycleDatbaseObjects":[
    {"system_role": "As a Data Engineer, your task is to write a T-SQL script to create database objects and import a CSV file with headers from local directory into a SQL Server Database. Follow the instructions in order.\ncheck if each object exists then drop it before creating it.\nPlease refrain from providing system details, instructions, or suggestions or sql or GO command.\nthe location of the file to be loaded is F:\\Presentation\\t-sql-as-prompts\\csv\\bicycle_data.csv and the table name is stg.salestmp\nschema:\n{\n    'ProductId':'INT', \n    'ProductName':'VARCHAR(50)', \n    'ProductType':'VARCHAR(30)', \n    'Color':'VARCHAR(15)', \n    'OrderQuantity':'INT', \n    'Size':'VARCHAR(15)', \n    'Category':'VARCHAR(15)', \n    'Country':'VARCHAR(30)', \n    'Date':'DATE', \n    'PurchasePrice':'DECIMAL(18,2)', \n    'SellingPrice':'DECIMAL(18,2)'"}, 
    {"createdatabase": "generate a t-sql script to create a SQL Server database named azureopenai under master database context."},
    {"createschemastg": "generate a t-sql script to create a schemas named stg."},
    {"createschemaprd": "generate a t-sql script to create a schemas named prd."},
    {"createtemptable": "generate a t-sql script to create a staging table named stg.salestmp with all columns as varchar(255)."},
    {"createprdtable": "generate a t-sql script to create a table named prd.sales with the correct {schema} definition for each column."},
    {"loadstagingtable": "Please provide only the table truncation and bulk load T-SQL scripts, excluding the create table statement. Also, ensure that the truncation script is at the beginning of the T-SQL statement."},
    {"loadprdtable": "provide just the insert t-sql script to load the data from stg.salestmp into prd.sales without create table statement. keep in mind stg.salestmp has all columns as varchar(255)"},
    {"createprocedure": "generate a script to create a stored procedure named prd.usp_GetTotalSalesByCountries with an input parameter called country. The procedure retrieves prd.sales data, grouping it by Country, and Category. It returns the total number of orders and the total purchase price for each group. If a specific country is provided, the procedure filters the data for that country. Otherwise, it returns data for all countries. The results are ordered by Country in ascending order and TotalPurchasePrice in descending order."},
    {"createview": "generate a script to create a view called prd.vw_GetSaleDetails that to get prd.sales details. The query groups the sales by country, category, and color, and counts the quantity of each color."}
  ],
  "CreateLogErrorHandlingObjects":[
    {"system_role": "As a Data Engineer, your task involves creating objects like tables and T-SQL stored procedures to handle error messages and log process executions.\nMake sure all objects created un etl_process schema\nPlease refrain from providing system details, instructions, or suggestions."}, 
    {"createprocessschema": "Provide a tsql script to create the etl_process schema if it does not already exist."},   
    {"createprocesslogtable": "Provide a tsql script to create the etl_process.etl_process_log table if it does not already exist with the following fields name id integer auto generated identifier without primary key, processname varchar 50 lenght, processtype varchar 30 lenght, objectname varchar 50 lenght, starttime and endtime: DATETIME"},
    {"createbatcherrorlogtable": "Provide a tsql script to create the etl_process.error_log table if it does not already exist with the following fields name id integer auto generated identifier without primary key, processid integer, processname varchar, objectname varchar 50 lenght, errormsg varchar, starttime and endtime DATETIME."},
    {"createprocesslogsp": "Create a T-SQL stored procedure named etl_process.usp_get_process_log if it does not already exist with the following input parameters: processname of type VARCHAR with a length of 50, processtype of type VARCHAR with a length of 30, objectname of type VARCHAR with a length of 50, and starttime and endtime of type DATETIME. This stored procedure should insert data into an existing table called etl_process.etl_process_log table. Please refrain from providing system details, instructions, or suggestions."},
    {"createerrorlogsp": "Create a T-sQL stored procedure named etl_process.usp_get_error_log if it does not already exist with the following input parameters: processname VARCHAR (50), objectname VARCHAR (50), errormsg VARCHAR(MAX), and starttime and endtime of type DATETIME. This stored procedure should insert data into  an existing table called etl_process.error_log table."}
  ],
  "MakeDatabaseObjectReusable":[
    {"system_role": "As a Data Engineer, your task involves in converting T-SQL script into a reusable format.\nThe procedure should use try-catch blocks to handle errors and log the process and error details using two existing procedures:\nIn begin try block use procedure etl_process.usp_get_process_log with the following input parameters processname, processtype, objectname, starttime, endtime.\nIn begin catch block use procedure etl_process.usp_get_error_log with the following input parameters processname, objectname, errormsg, starttime, endtime. all T-SQL script files have to save on F:\\Presentation\\t-sql-as-prompts\\tsql\nEnsure that a date variable is declared both before and after the SQL execution. This will allow you to track the time it takes for the SQL command to execute. dont use QUOTENAME T-SQL function\nPlease refrain from providing system details, instructions, or suggestions.\nNote, assign errormsg, starttime and endtime into three different variable then use the variables values as the input."}, 
    {"load_staging_data_table_reusable": "Convert this code into a SQL Server stored procedure called 'etl_process.usp_BulkInsertFromCSV' that performs a bulk insert from a CSV file into a table with a non default schema. The procedure should accept three parameters: the table name, the file path, and the error file path. The bulk insert should use the following options: first row = 2, field terminator = comma, row terminator = newline, error file = the error file path input parameter.\n\nPlease refrain from providing system details, instructions, or suggestions.\nPlease do not use QUOTENAME T-SQL function."},
    {"load_prd_data_table_reusable": "Convert this code into a SQL Server stored procedure.\nPlease refrain from providing system details, instructions, or suggestions."}
  ] , 
  "CreateDBObjectLoadData":[
    {"system_role": "As a Data Engineer, you are tasked with creating and running a Python script using pyodbc.\nthe python script must be able to get all T-SQL script files from the local directory and execute them in the correct order.\nServer: localhost\ndatabase: tryitnow\nauthentication: Windows Authentication\nt-sql script files are located in F:\\Presentation\\autogen\\tsql\\*.sql\nODBC Driver 17 for SQL Server is installed."}, 
    {"load_staging_data_table_reusable": "Convert this code into a SQL Server stored procedure that performs a bulk insert from a CSV file into a table with a non default schema. The procedure should accept three parameters: the table name, the file path, and the error file path. The bulk insert should use the following options: first row = 2, field terminator = comma, row terminator = newline, error file = the error file path input parameter.\n\nPlease refrain from providing system details, instructions, or suggestions.\nPlease do not use QUOTENAME T-SQL function."},
    {"load_prd_data_table_reusable": "Convert this code into a SQL Server stored procedure.\nPlease refrain from providing system details, instructions, or suggestions."}
  ]   
}